import cv2
import numpy as np
import tensorrt as trt
import pycuda.driver as cuda
import pycuda.autoinit
import time
import os

# Centroid tracking class
class CentroidTracker:
    def __init__(self, max_disappeared=50):
        self.next_object_id = 0
        self.objects = {}
        self.disappeared = {}
        self.max_disappeared = max_disappeared

    def register(self, centroid):
        self.objects[self.next_object_id] = centroid
        self.disappeared[self.next_object_id] = 0
        self.next_object_id += 1

    def deregister(self, object_id):
        del self.objects[object_id]
        del self.disappeared[object_id]

    def update(self, boxes):
        if len(boxes) == 0:
            for box_id in list(self.disappeared.keys()):
                self.disappeared[box_id] += 1
                if self.disappeared[box_id] > self.max_disappeared:
                    self.deregister(box_id)
            return self.objects

        centroids = np.array([[box[0], box[1]] for box in boxes])

        if len(self.objects) == 0:
            for centroid in centroids:
                self.register(centroid)
        else:
            object_ids = list(self.objects.keys())
            object_centroids = np.array(list(self.objects.values()))
            distances = np.sqrt(((object_centroids[:, np.newaxis] - centroids) ** 2).sum(axis=2))
            rows = distances.min(axis=1).argsort()
            cols = distances.argmin(axis=1)[rows]
            used_rows, used_cols = set(), set()
            for row, col in zip(rows, cols):
                if row in used_rows or col in used_cols:
                    continue
                object_id = object_ids[row]
                self.objects[object_id] = centroids[col]
                self.disappeared[object_id] = 0
                used_rows.add(row)
                used_cols.add(col)
            unused_rows = set(range(distances.shape[0])).difference(used_rows)
            unused_cols = set(range(distances.shape[1])).difference(used_cols)
            for row in unused_rows:
                object_id = object_ids[row]
                self.disappeared[object_id] += 1
                if self.disappeared[object_id] > self.max_disappeared:
                    self.deregister(object_id)
            for col in unused_cols:
                self.register(centroids[col])

        return self.objects

# TensorRT inference class
class TRTInference:
    def __init__(self, engine_path, input_shape=(640, 640)):
        self.logger = trt.Logger(trt.Logger.WARNING)
        with open(engine_path, 'rb') as f, trt.Runtime(self.logger) as runtime:
            self.engine = runtime.deserialize_cuda_engine(f.read())
        self.context = self.engine.create_execution_context()
        self.input_shape = input_shape
        self.inputs, self.outputs, self.bindings, self.stream = self.allocate_buffers()
        self.input_size = trt.volume(self.engine.get_tensor_shape(self.engine.get_tensor_name(0))) * trt.DataType.FLOAT.itemsize

    def allocate_buffers(self):
        inputs = []
        outputs = []
        bindings = []
        stream = cuda.Stream()
        for binding in range(self.engine.num_io_tensors):
            tensor_name = self.engine.get_tensor_name(binding)
            size = trt.volume(self.engine.get_tensor_shape(tensor_name))
            dtype = trt.nptype(self.engine.get_tensor_dtype(tensor_name))
            host_mem = cuda.pagelocked_empty(size, dtype)
            device_mem = cuda.mem_alloc(host_mem.nbytes)
            bindings.append(int(device_mem))
            if self.engine.get_tensor_mode(tensor_name) == trt.TensorIOMode.INPUT:
                inputs.append({'host': host_mem, 'device': device_mem})
            else:
                outputs.append({'host': host_mem, 'device': device_mem})
        return inputs, outputs, bindings, stream

    def preprocess(self, image):
        img = cv2.resize(image, self.input_shape)
        img = img.astype(np.float32) / 255.0
        img = img.transpose(2, 0, 1)  # HWC to CHW
        img = np.ascontiguousarray(img)
        return img

    def postprocess(self, outputs, conf_thres=0.5):
        boxes = []
        scores = []
        output = outputs[0]['host']
        num_boxes = output.shape[1]
        for i in range(num_boxes):
            conf = output[0, i, 4]
            if conf > conf_thres:
                x, y, w, h = output[0, i, :4]
                boxes.append([x, y, w, h])
                scores.append(conf)
        return np.array(boxes), np.array(scores)

    def infer(self, image):
        input_image = self.preprocess(image)
        np.copyto(self.inputs[0]['host'], input_image.ravel())
        cuda.memcpy_htod_async(self.inputs[0]['device'], self.inputs[0]['host'], self.stream)
        self.context.execute_async_v2(bindings=self.bindings, stream_handle=self.stream.handle)
        cuda.memcpy_dtoh_async(self.outputs[0]['host'], self.outputs[0]['device'], self.stream)
        self.stream.synchronize()
        boxes, scores = self.postprocess(self.outputs)
        return boxes, scores

# Define helper functions
def crop_face(frame, box):
    x, y, w, h = box
    x1, y1 = int(x - w / 2), int(y - h / 2)
    x2, y2 = int(x + w / 2), int(y + h / 2)
    x1, y1 = max(0, x1), max(0, y1)
    x2, y2 = min(frame.shape[1], x2), min(frame.shape[0], y2)
    if x2 <= x1 or y2 <= y1:
        print(f"Invalid crop: x1={x1}, y1={y1}, x2={x2}, y2={y2}")
        return np.array([])
    return frame[y1:y2, x1:x2]

# Initialize model and output directory
output_dir = "/home/jetson/Downloads/faces"
os.makedirs(output_dir, exist_ok=True)
trt_model = TRTInference("/home/jetson/Downloads/yolov8n-face.trt")

# Initialize tracker and state
tracker = CentroidTracker(max_disappeared=30)
saved_faces = {}
time_window = 5

# Process RTSP stream
pipeline = "rtspsrc location=rtsp://admin:FYP12345@10.40.16.236:554/Streaming/Channels/101 ! rtph264depay ! h264parse ! nvv4l2decoder ! nvvidconv ! videoconvert ! video/x-raw,format=BGR ! appsink"
print(f"Attempting to open RTSP stream with pipeline: {pipeline}")
cap = cv2.VideoCapture(pipeline, cv2.CAP_GSTREAMER)
if not cap.isOpened():
    print("Failed to open RTSP stream")
    exit(1)

frame_count = 0
while True:
    ret, frame = cap.read()
    if not ret:
        print("Failed to read frame")
        break
    frame_count += 1

    # Detect faces (using TensorRT)
    boxes, scores = trt_model.infer(frame)
    print(f"Frame {frame_count}: Detected {len(boxes)} faces")

    # Update tracker
    tracked_objects = tracker.update(boxes)
    current_detections = []
    for i, (box, score) in enumerate(zip(boxes, scores)):
        if score > 0.5:
            face_crop = crop_face(frame, box)
            if face_crop.size == 0:
                print(f"Frame {frame_count}: Empty face crop for box {box}")
                continue
            current_detections.append({"box": box, "score": score, "face_crop": face_crop})
        else:
            print(f"Frame {frame_count}: Skipped face {i} with low confidence {score:.2f}")

    print(f"Frame {frame_count}: {len(current_detections)} valid detections")

    # Assign track IDs to detections
    for track_id, centroid in tracked_objects.items():
        min_dist = float('inf')
        best_detection = None
        for detection in current_detections:
            box = detection["box"]
            detection_centroid = np.array([box[0], box[1]])
            dist = np.sqrt(((centroid - detection_centroid) ** 2).sum())
            if dist < min_dist:
                min_dist = dist
                best_detection = detection

        if best_detection is None:
            print(f"Frame {frame_count}: No detection matched for track {track_id}")
            continue

        face_crop = best_detection["face_crop"]
        score = best_detection["score"]
        current_time = time.time()

        # Check if this track_id was recently saved
        if track_id in saved_faces:
            last_saved_time = saved_faces[track_id]
            if (current_time - last_saved_time) < time_window:
                print(f"Frame {frame_count}: Skipping track {track_id} (recently saved at {last_saved_time})")
                continue

        # Save the face
        if face_crop.size > 0:
            filename = f"{output_dir}/face_{track_id}.jpg"
            print(f"Frame {frame_count}: Attempting to save face to {filename}")
            success = cv2.imwrite(filename, face_crop)
            if success:
                saved_faces[track_id] = current_time
                print(f"Frame {frame_count}: Saved face for track {track_id} (score {score:.2f})")
            else:
                print(f"Frame {frame_count}: Failed to save face for track {track_id} to {filename}")

cap.release()
print("Processing complete.")
